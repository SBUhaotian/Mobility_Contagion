{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "import gc\n",
    "PROJ_HOME = \"../\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process and build the poi and check-in datasets for city / country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract city / country checkins.\n",
    "# Get GB_POIs by this: grep GB raw_POIs.txt > GB_POI.txt\n",
    "\n",
    "def select_city_pois(cityname, North, South, West, East):\n",
    "    chunksize = 10 ** 5\n",
    "    i = 0\n",
    "    filename = \"raw_POIs.txt\"\n",
    "    for df in pd.read_csv(filename, chunksize=chunksize, \\\n",
    "                          names=['venueId', 'Lat','Long','venueCat', 'Country'], sep='\\t'):\n",
    "        local_poi_df = df.loc[(df['Lat'] >= South) & (df['Lat'] <= North) &\\\n",
    "                         (df['Long'] >= West) & (df['Long'] <= East)]\n",
    "        if (i == 0):\n",
    "            local_poi_df[['venueId', 'venueCat']].to_csv(cityname+'_pois.csv', index=False)\n",
    "        else:\n",
    "            local_poi_df[['venueId', 'venueCat']].to_csv(cityname+'_pois.csv', mode='a',\\\n",
    "                                                         header=False, index=False)\n",
    "        i = i+1\n",
    "        #if (i % 100 == 0):\n",
    "        #print (i, len(local_poi_df))\n",
    "        del df\n",
    "        gc.collect()\n",
    "\n",
    "def select_country_pois(country):\n",
    "    chunksize = 10 ** 5\n",
    "    i = 0\n",
    "    filename = \"raw_POIs.txt\"\n",
    "    for df in pd.read_csv(filename, chunksize=chunksize, \\\n",
    "                          names=['venueId', 'Lat','Long','venueCat', 'country'], sep='\\t'):\n",
    "        local_poi_df = df.loc[(df['country'].eq(country))]\n",
    "        if (i == 0):\n",
    "            local_poi_df[['venueId', 'Lat','Long', 'venueCat']].to_csv(country+'_pois.csv', index=False)\n",
    "        else:\n",
    "            local_poi_df[['venueId', 'Lat','Long', 'venueCat']].to_csv(country+'_pois.csv', mode='a',\\\n",
    "                                                         header=False, index=False)\n",
    "        i = i+1\n",
    "        if (i % 100 == 0):\n",
    "            print (i, len(local_poi_df), local_poi_df.head())\n",
    "        del df\n",
    "        gc.collect()\n",
    "\n",
    "#select_city_pois(\"london\", North = 51.7661, South = 51.2275, West = -0.7663, East = 0.6592)\n",
    "#select_city_pois(\"nyc\", North=41.0131, South=40.5378, West=-74.3074, East=-73.4532)\n",
    "#select_city_pois(\"Tokyo\", North=36.919, South=34.827, West=138.535, East=141.103)\n",
    "#select_city_pois(\"los_angeles\", North = 35.586, South = 31.896, West = -120.521, East = -114.763)\n",
    "#select_city_pois(\"chicago\", North = 42.593, South = 41.290, West = -88.759, East = -86.633)\n",
    "#select_city_pois(\"istambul\", North = 41.3500, South = 40.8046, West = 28.5109, East = 29.4456)\n",
    "select_city_pois(\"jakarta\", North = -6.0054, South = -6.5173, West = 106.4232, East = 107.3680)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 107\n",
      "200 668\n",
      "300 409\n",
      "400 561\n",
      "500 216\n",
      "600 310\n",
      "700 633\n",
      "800 277\n",
      "900 344\n",
      "len(place_df): 472186\n",
      "len(decent_users): 564\n",
      "472 45657 12773\n"
     ]
    }
   ],
   "source": [
    "def select_city_checkins(outfilename, poi_filename):\n",
    "    def convert_time(arg):\n",
    "        try:\n",
    "            xx = arg['UTCTime'].split('+')\n",
    "            timestr = xx[0]+xx[1].split(' ')[1]\n",
    "            a = datetime.strptime(timestr, '%a %b %d %H:%M:%S %Y')\n",
    "            local_time = a + timedelta(minutes=float(arg['timeoffset']))\n",
    "            hour = local_time.timestamp()/3600.\n",
    "            #print (\"hour:\", hour)\n",
    "            return hour\n",
    "        except Exception:\n",
    "            print (\"error! arg:\", arg)\n",
    "            return np.nan\n",
    "\n",
    "    #'''\n",
    "    place_pois = pd.read_csv(poi_filename).venueId\n",
    "    input_filename = 'raw_Checkins_anonymized.txt'\n",
    "    i = 0\n",
    "    #place_df = pd.DataFrame()\n",
    "    chunksize = 10 ** 5\n",
    "    \n",
    "    names = ['userId', 'venueId', 'UTCTime', 'timeoffset']\n",
    "    for df in pd.read_csv(input_filename, chunksize=chunksize, names=names, sep='\\t'):\n",
    "        _place_df = df[df['venueId'].isin(place_pois)].copy()\n",
    "        #print (_place_df.iloc[0]); return\n",
    "        \n",
    "        if (len(_place_df) == 0):\n",
    "            continue\n",
    "        #print (_place_df)\n",
    "        #return\n",
    "        _place_df['posixtime'] = _place_df.apply(convert_time, axis=1)\n",
    "        \n",
    "        #place_df = place_df.append(_place_df, ignore_index=True)\n",
    "        \n",
    "        if (i == 0):\n",
    "            _place_df[['userId', 'venueId', 'posixtime']].\\\n",
    "                        to_csv(\"/tmp/_intermediate.csv\", index = False)\n",
    "        else:\n",
    "            _place_df[['userId', 'venueId', 'posixtime']].to_csv(\"/tmp/_intermediate.csv\",\\\n",
    "                                                              mode='a', header=False, index=False)\n",
    "        \n",
    "        i = i+1\n",
    "        if (i % 100 == 0):\n",
    "            print (i, len(_place_df))\n",
    "            #break\n",
    "        del df\n",
    "        del _place_df\n",
    "        gc.collect()\n",
    "    \n",
    "    place_df = pd.read_csv(\"/tmp/_intermediate.csv\")\n",
    "    print (\"len(place_df):\", len(place_df))\n",
    "    place_df = place_df.sort_values('posixtime', ascending=True).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    #'''\n",
    "    xf = place_df.groupby('userId').count()[['venueId']]\n",
    "    decent_users = xf[xf['venueId'] > 100].index\n",
    "    print (\"len(decent_users):\", len(decent_users))\n",
    "    filter_df = place_df[place_df['userId'].isin(decent_users)].copy()\n",
    "    filter_df = filter_df.sort_values('posixtime', ascending=True).reset_index(drop=True)\n",
    "    \n",
    "    start_time = filter_df.iloc[0]['posixtime']\n",
    "    filter_df[\"posixtime\"] = filter_df[\"posixtime\"].apply(lambda x: x - start_time)\n",
    "    filter_df = filter_df[filter_df['posixtime'] <= 150*24]\n",
    "    \n",
    "    print (len(filter_df.userId.unique()), len(filter_df), len(filter_df.venueId.unique()))\n",
    "    \n",
    "    filter_df.to_csv(outfilename, index=False)\n",
    "\n",
    "#select_city_checkins(PROJ_HOME+\"data/nyc/checkin.csv\", \"nyc_pois.csv\")\n",
    "#select_city_checkins(\"US.csv\", \"US_pois.csv\")\n",
    "#select_city_checkins(\"FR.csv\", \"FR_pois.csv\")\n",
    "#select_city_checkins(\"Tokyo.csv\", \"Tokyo_pois.csv\")\n",
    "select_city_checkins(\"london.csv\", \"london_pois.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
